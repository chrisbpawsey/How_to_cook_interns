\subsubsection{LAMMPS}

LAMMPS is a traditional molecular dynamics code. It is also an acronym for Large-scale Atomic/Molecular Massively Parallel Simulator. It has potentials
for solid state materials which include metals and semicoductors. It also has potential for delicate matter i.e biomolecules and polymers and
coarse-grained or mesoscopic systems.

LAMMPS is an easy tool used to model atoms or rather, as a parallel molecule test simulator at the atomic, meso, or continuum scale. This tool runs on
single processors or in parallel, making the use of message-passing systems (MPI) and a spatial-decomposition of the simulator domain. A significant
number of its models have forms that give accelerated performance on CPUs, GPUs, and Intel Xeon Phi processors.

The LAMMPS example done in the \emph{getexample} tool was specifically run on Magnus. The source code had been provided with a large number of atoms and their
properties and potentials. The existing SLURM file of the MPI tasks of Magnus was utilized and modified to request a total of 2 nodes. The partition
remained as \emph{debugq.} The time was changed to 20 minutes as an increase in time would be better because it gives sufficient time to run the code. If the 
time is not long enough, it kills the job once the time runs out.

The following commands show the SLURM directives needed for the LAMMPS task:

\begin{tcolorbox}
\begin{Verbatim}[fontsize=\scriptsize]
#!/bin/bash -l
#SBATCH --job-name=hostname
#SBATCH --partition=debugq
#SBATCH --nodes=2
#SBATCH --time=00:20:00
#SBATCH --export=NONE
\end{Verbatim}
\end{tcolorbox}

The program environment used for this task was GNU, hence the module was swapped from Cray to GNU and and lammps module was loaded which was required
to compile the source code. 

\begin{tcolorbox}
\begin{Verbatim}[fontsize=\scriptsize]
module swap PrgEnv-cray PrgEnv-gnu
module load lammps
\end{Verbatim}
\end{tcolorbox}

In the template of the SLURM, an executable, a results directory and an output were declared to store the results of the LAMMPS example in the GROUP 
with the filenames below:

\begin{tcolorbox}
\begin{Verbatim}[fontsize=\scriptsize]
EXECUTABLE=lmp_mpi
SCRATCH=$MYSCRATCH/run_lammps/$SLURM_JOBID
RESULTS=$MYGROUP/lmp_mpi_results/$SLURM_JOBID

OUTPUT=lammps_mpi.log
\end{Verbatim}
\end{tcolorbox}

Before running the example on the scratch, the files ending with .lmp name which contain the input data were copied to the scratch and this was
obtained in the SLURM as:

\begin{tcolorbox}
\begin{Verbatim}[fontsize=\scriptsize]
cp *.lmp $SCRATCH
\end{Verbatim}
\end{tcolorbox}

As this LAMMPS example is an MPI task, it was run on Magnus on 2 nodes with 24 MPI tasks per node giving a total of 48 tasks with the executable working
on the data set called \emph{emp2.lmp} and this was implemented with the aprun command to launch the job:

\begin{tcolorbox}
\begin{Verbatim}[fontsize=\scriptsize]
aprun -n 48 -N 24 $EXECUTABLE < epm2.lmp >> ${OUTPUT}
\end{Verbatim}
\end{tcolorbox}

The SLURM was submitted to Magnus by the identical sbatch command used in the README files of all the Magnus examples.

